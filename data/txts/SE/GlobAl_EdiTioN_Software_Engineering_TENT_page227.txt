˜˚˛˝˙ˆˇ˘˜˜˜˜˜˜˜˜
Testing is intended to show that a program does what it is intended to do and to 
 discover program defects before it is put into use. When you test software, you exe-cute a program using artificial data. You check the results of the test run for errors, 

anomalies, or information about the program™s non-functional attributes.When you test software, you are trying to do two things:1.
 Demonstrate to the developer and the customer that the software meets its 

requirements. For custom software, this means that there should be at least one 

test for every requirement in the requirements document. For generic software 

products, it means that there should be tests for all of the system features that 
will be included in the product release. You may also test combinations of fea-
tures to check for unwanted interactions between them.2. Find inputs or input sequences where the behavior of the software is incorrect, 
undesirable, or does not conform to its specification. These are caused by defects 
(bugs) in the software. When you test software to find defects, you are trying to 
root out undesirable system behavior such as system crashes, unwanted interac-
tions with other systems, incorrect computations, and data corruption.The first of these is validation testing, where you expect the system to perform correctly using a set of test cases that reflect the system™s expected use. The  second is defect testing, where the test cases are designed to expose defects. The test cases in 
defect testing can be deliberately obscure and need not reflect how the system is 

normally used. Of course, there is no definite boundary between these two approaches 

to testing. During validation testing, you will find defects in the 
 system; during 
defect testing, some of the tests will show that the program meets its requirements.Figure 8.
1 shows the differences between validation testing and defect testing. Think 
of the system being tested as a black box. The system accepts inputs from some input 

set I and generates outputs in an output set O. Some of the outputs will be erroneous. 
These are the outputs in set Oe that are generated by the system in response to inputs in 
the set Ie. The priority in defect testing is to find those inputs in˜the set 
Ie because these 
reveal problems with the system. Validation testing involves testing with correct inputs 

that are outside Ie. These stimulate the system to generate the expected correct outputs.Testing cannot demonstrate that the software is free of defects or that it will behave 
as specified in every circumstance. It is always possible that a test you have overlooked 

could discover further problems with the system. As Edsger Dijkstra, an early con-
tributor to the development of software engineering, eloquently stated (Dijkstra 1972):ﬁTesting can only show the presence of errors, not their absence ƒﬂTesting is part of a broader process of software verification and validation (V & V). 
Verification and validation are not the same thing, although they are often  confused. 
Barry Boehm, a pioneer of software engineering, succinctly expressed the difference 

between them (Boehm 1979):ƒDijkstra, E. W. 1972. ﬁThe Humble Programmer.ﬂ Comm. ACM 15 (10): 859Œ66. doi:10.1145/ 
355604.361591